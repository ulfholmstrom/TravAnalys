{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ny modell. Nu delar vi upp datat på omgångarna, inte slumpmässigt. Totalt 222 omgångar. Bygger modell på 175 omgångar, validerar på de övriga. Imputerar för missing innan vi kör modellen, tar bort detta steg från data pipelinen. Vi läser även in VNUM som är rankingen efter spelade hästar för att jämföra med den framtagna modellen__\n",
    "\n",
    "__Tar fram optimal modell med cross validering samt utvärderar på de omgångar som plockats bort för att komma fram till ett förväntat väntevärde på ramen. Jämför med VNUM. Vi testar även med att plocka de 4 fyra högst scorade hästarna per lopp, istället för att göra ett total uttag på Score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Necessary Sklearn objects used in the analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_excel('DataV75TillUffe_2019-02-01_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en unik nyckel på lopp: Gör om Datum och lopp till en sträng\n",
    "\n",
    "df0['cdate'] = df0.Datum.astype('object')\n",
    "df0['cLopp'] = df0.Lopp.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['Key'] = df0['cdate'].astype(str) + df0['cLopp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.Key.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Skapar en målvariabel - vinnare__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['Y'] = np.where(df0['Plac'].isin([1]), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plockar bort de variabler som inte ska med__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df0.copy(deep = True)\n",
    "# Alla analysvariabler\n",
    "df1 = df1. \\\n",
    "drop(['Utdelning','Plac','cdate','cLopp','V_ODDS','S_R', \\\n",
    "      'V75PROC','TK_R','Arstid','Distans','Startsatt','SP_R','Ex_R','R_R','P_R','GRUPP'], axis = 1). \\\n",
    "copy().set_index(['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17994 entries, 2016-05-21 00:00:001 to 2019-01-05 00:00:007\n",
      "Data columns (total 25 columns):\n",
      "Datum          17994 non-null datetime64[ns]\n",
      "Lopp           17994 non-null int64\n",
      "Hast           17994 non-null int64\n",
      "VLP            17994 non-null float64\n",
      "VNUM           17994 non-null int64\n",
      "SVLP           17994 non-null float64\n",
      "VSVLP          17994 non-null float64\n",
      "VPN_SUM        17994 non-null float64\n",
      "VPN_SUM_ORD    17994 non-null int64\n",
      "VPK_SUM        17994 non-null float64\n",
      "VPK_SUM_ORD    17994 non-null int64\n",
      "VLPB           17994 non-null float64\n",
      "SVLPB          17994 non-null float64\n",
      "VSVLPB         17994 non-null float64\n",
      "E_P            17994 non-null float64\n",
      "E_P_Num        17994 non-null int64\n",
      "E_N            17994 non-null float64\n",
      "E_R            17994 non-null float64\n",
      "E_U            17994 non-null float64\n",
      "G_R            16243 non-null float64\n",
      "A_R            15310 non-null float64\n",
      "T_R            16317 non-null float64\n",
      "ToR            15201 non-null float64\n",
      "Ts_R           17994 non-null int64\n",
      "Y              17994 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(16), int64(8)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterera över varje kolumn och använd logiken nedan\n",
    "# Checkar dessa variabler [G_R , A_R, ToR , P_R ]\n",
    "# Skapar en lista som håller de unika datumen för dessa när missing förekommer\n",
    "# Tar sedan bort dessa lopp och bygger modell på de kvarvarande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['mflag1'] = np.where(df1.G_R.isna(),True,False)\n",
    "df1['mflag2'] = np.where(df1.A_R.isna(),True,False)\n",
    "df1['mflag3'] = np.where(df1.ToR.isna(),True,False)\n",
    "#df1['mflag4'] = np.where(df1.P_R.isna(),True,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_delete = df1[(df1.mflag1 | df1.mflag2 | df1.mflag3 | df1.mflag4)]\n",
    "\n",
    "df_delete = df1[(df1.mflag1 | df1.mflag2 | df1.mflag3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3800"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_filter = df_delete.Datum.drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.Datum.isin(date_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14194 entries, 2016-07-26 00:00:001 to 2019-01-05 00:00:007\n",
      "Data columns (total 28 columns):\n",
      "Datum          14194 non-null datetime64[ns]\n",
      "Lopp           14194 non-null int64\n",
      "Hast           14194 non-null int64\n",
      "VLP            14194 non-null float64\n",
      "VNUM           14194 non-null int64\n",
      "SVLP           14194 non-null float64\n",
      "VSVLP          14194 non-null float64\n",
      "VPN_SUM        14194 non-null float64\n",
      "VPN_SUM_ORD    14194 non-null int64\n",
      "VPK_SUM        14194 non-null float64\n",
      "VPK_SUM_ORD    14194 non-null int64\n",
      "VLPB           14194 non-null float64\n",
      "SVLPB          14194 non-null float64\n",
      "VSVLPB         14194 non-null float64\n",
      "E_P            14194 non-null float64\n",
      "E_P_Num        14194 non-null int64\n",
      "E_N            14194 non-null float64\n",
      "E_R            14194 non-null float64\n",
      "E_U            14194 non-null float64\n",
      "G_R            14194 non-null float64\n",
      "A_R            14194 non-null float64\n",
      "T_R            14194 non-null float64\n",
      "ToR            14194 non-null float64\n",
      "Ts_R           14194 non-null int64\n",
      "Y              14194 non-null int64\n",
      "mflag1         14194 non-null bool\n",
      "mflag2         14194 non-null bool\n",
      "mflag3         14194 non-null bool\n",
      "dtypes: bool(3), datetime64[ns](1), float64(16), int64(8)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.drop(['mflag1', 'mflag2','mflag3','mflag4'], axis = 1)\n",
    "df1 = df1.drop(['mflag1', 'mflag2','mflag3'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gör om grupp till objekt\n",
    "#df1['GRUPP'] = df1.GRUPP.astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Delar upp i numeriska samt charachter attribut. Det är dessa som går in i modellen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = [] \n",
    "cat_attribs = [] \n",
    "\n",
    "for var, typ in zip(df1.columns[:-1], df1.dtypes[:-1]): \n",
    "    if typ == 'object': \n",
    "        cat_attribs.append(var) \n",
    "    elif (typ != 'datetime64[ns]') & (var != 'VNUM') & (var != 'Hast') & (var != 'Lopp'): \n",
    "        num_attribs.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VLP',\n",
       " 'SVLP',\n",
       " 'VSVLP',\n",
       " 'VPN_SUM',\n",
       " 'VPN_SUM_ORD',\n",
       " 'VPK_SUM',\n",
       " 'VPK_SUM_ORD',\n",
       " 'VLPB',\n",
       " 'SVLPB',\n",
       " 'VSVLPB',\n",
       " 'E_P',\n",
       " 'E_P_Num',\n",
       " 'E_N',\n",
       " 'E_R',\n",
       " 'E_U',\n",
       " 'G_R',\n",
       " 'A_R',\n",
       " 'T_R',\n",
       " 'ToR',\n",
       " 'Ts_R']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs.append('V75PROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VLP',\n",
       " 'SVLP',\n",
       " 'VSVLP',\n",
       " 'VPN_SUM',\n",
       " 'VPN_SUM_ORD',\n",
       " 'VPK_SUM',\n",
       " 'VPK_SUM_ORD',\n",
       " 'VLPB',\n",
       " 'SVLPB',\n",
       " 'VSVLPB',\n",
       " 'E_P',\n",
       " 'E_P_Num',\n",
       " 'E_N',\n",
       " 'E_R',\n",
       " 'E_U',\n",
       " 'G_R',\n",
       " 'A_R',\n",
       " 'T_R',\n",
       " 'ToR',\n",
       " 'Ts_R',\n",
       " 'V75PROC']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df0[num_attribs].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VLP</th>\n",
       "      <th>SVLP</th>\n",
       "      <th>VSVLP</th>\n",
       "      <th>VPN_SUM</th>\n",
       "      <th>VPN_SUM_ORD</th>\n",
       "      <th>VPK_SUM</th>\n",
       "      <th>VPK_SUM_ORD</th>\n",
       "      <th>VLPB</th>\n",
       "      <th>SVLPB</th>\n",
       "      <th>VSVLPB</th>\n",
       "      <th>...</th>\n",
       "      <th>E_P_Num</th>\n",
       "      <th>E_N</th>\n",
       "      <th>E_R</th>\n",
       "      <th>E_U</th>\n",
       "      <th>G_R</th>\n",
       "      <th>A_R</th>\n",
       "      <th>T_R</th>\n",
       "      <th>ToR</th>\n",
       "      <th>Ts_R</th>\n",
       "      <th>V75PROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VLP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071263</td>\n",
       "      <td>-0.367367</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>-0.067348</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.960169</td>\n",
       "      <td>0.969106</td>\n",
       "      <td>0.944690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757096</td>\n",
       "      <td>-0.267246</td>\n",
       "      <td>-0.811654</td>\n",
       "      <td>-0.522635</td>\n",
       "      <td>0.037025</td>\n",
       "      <td>0.038832</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.037687</td>\n",
       "      <td>0.037157</td>\n",
       "      <td>0.056450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVLP</th>\n",
       "      <td>-0.071263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169084</td>\n",
       "      <td>0.038347</td>\n",
       "      <td>-0.042245</td>\n",
       "      <td>0.035518</td>\n",
       "      <td>-0.029882</td>\n",
       "      <td>-0.139038</td>\n",
       "      <td>-0.180037</td>\n",
       "      <td>-0.299864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111790</td>\n",
       "      <td>-0.088104</td>\n",
       "      <td>-0.222558</td>\n",
       "      <td>-0.186449</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.030145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSVLP</th>\n",
       "      <td>-0.367367</td>\n",
       "      <td>0.169084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>-0.015119</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>-0.037124</td>\n",
       "      <td>-0.368311</td>\n",
       "      <td>-0.442444</td>\n",
       "      <td>-0.404693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342066</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>0.242574</td>\n",
       "      <td>0.082371</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.007657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPN_SUM</th>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.038347</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.896917</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.040302</td>\n",
       "      <td>0.038096</td>\n",
       "      <td>0.032319</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043809</td>\n",
       "      <td>-0.098431</td>\n",
       "      <td>-0.059658</td>\n",
       "      <td>-0.061530</td>\n",
       "      <td>0.081903</td>\n",
       "      <td>0.206301</td>\n",
       "      <td>0.188231</td>\n",
       "      <td>0.182724</td>\n",
       "      <td>0.192329</td>\n",
       "      <td>0.418248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPN_SUM_ORD</th>\n",
       "      <td>-0.067348</td>\n",
       "      <td>-0.042245</td>\n",
       "      <td>-0.015119</td>\n",
       "      <td>-0.896917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.190501</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>-0.045149</td>\n",
       "      <td>-0.042867</td>\n",
       "      <td>-0.036507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>0.114461</td>\n",
       "      <td>0.072339</td>\n",
       "      <td>0.069085</td>\n",
       "      <td>-0.071170</td>\n",
       "      <td>-0.212356</td>\n",
       "      <td>-0.187838</td>\n",
       "      <td>-0.185484</td>\n",
       "      <td>-0.195101</td>\n",
       "      <td>-0.372038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPK_SUM</th>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.035518</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.209983</td>\n",
       "      <td>-0.190501</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.735108</td>\n",
       "      <td>0.027460</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032890</td>\n",
       "      <td>-0.061277</td>\n",
       "      <td>-0.046734</td>\n",
       "      <td>-0.053895</td>\n",
       "      <td>0.165985</td>\n",
       "      <td>0.243502</td>\n",
       "      <td>0.258829</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>0.266919</td>\n",
       "      <td>0.519214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VPK_SUM_ORD</th>\n",
       "      <td>0.001102</td>\n",
       "      <td>-0.029882</td>\n",
       "      <td>-0.037124</td>\n",
       "      <td>-0.197619</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>-0.735108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004979</td>\n",
       "      <td>0.082030</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>-0.195818</td>\n",
       "      <td>-0.290289</td>\n",
       "      <td>-0.301351</td>\n",
       "      <td>-0.211739</td>\n",
       "      <td>-0.314897</td>\n",
       "      <td>-0.470052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VLPB</th>\n",
       "      <td>0.960169</td>\n",
       "      <td>-0.139038</td>\n",
       "      <td>-0.368311</td>\n",
       "      <td>0.040302</td>\n",
       "      <td>-0.045149</td>\n",
       "      <td>0.027460</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971581</td>\n",
       "      <td>0.961246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.682341</td>\n",
       "      <td>-0.193377</td>\n",
       "      <td>-0.747055</td>\n",
       "      <td>-0.475716</td>\n",
       "      <td>0.025570</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.026626</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.026505</td>\n",
       "      <td>0.039777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVLPB</th>\n",
       "      <td>0.969106</td>\n",
       "      <td>-0.180037</td>\n",
       "      <td>-0.442444</td>\n",
       "      <td>0.038096</td>\n",
       "      <td>-0.042867</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.971581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.207277</td>\n",
       "      <td>-0.780415</td>\n",
       "      <td>-0.474077</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.024808</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.036953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VSVLPB</th>\n",
       "      <td>0.944690</td>\n",
       "      <td>-0.299864</td>\n",
       "      <td>-0.404693</td>\n",
       "      <td>0.032319</td>\n",
       "      <td>-0.036507</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.961246</td>\n",
       "      <td>0.988131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.700718</td>\n",
       "      <td>-0.190424</td>\n",
       "      <td>-0.712983</td>\n",
       "      <td>-0.431286</td>\n",
       "      <td>0.020043</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.021230</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>0.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_P</th>\n",
       "      <td>0.976880</td>\n",
       "      <td>-0.078638</td>\n",
       "      <td>-0.379678</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>-0.054412</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>0.013088</td>\n",
       "      <td>0.962856</td>\n",
       "      <td>0.988286</td>\n",
       "      <td>0.963110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.806287</td>\n",
       "      <td>-0.236096</td>\n",
       "      <td>-0.828605</td>\n",
       "      <td>-0.518892</td>\n",
       "      <td>0.028921</td>\n",
       "      <td>0.031676</td>\n",
       "      <td>0.031265</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>0.029124</td>\n",
       "      <td>0.045251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_P_Num</th>\n",
       "      <td>-0.757096</td>\n",
       "      <td>-0.111790</td>\n",
       "      <td>0.342066</td>\n",
       "      <td>-0.043809</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>-0.032890</td>\n",
       "      <td>-0.004979</td>\n",
       "      <td>-0.682341</td>\n",
       "      <td>-0.759554</td>\n",
       "      <td>-0.700718</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237266</td>\n",
       "      <td>0.828517</td>\n",
       "      <td>0.486007</td>\n",
       "      <td>-0.027471</td>\n",
       "      <td>-0.031283</td>\n",
       "      <td>-0.029904</td>\n",
       "      <td>-0.027742</td>\n",
       "      <td>-0.026310</td>\n",
       "      <td>-0.040442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_N</th>\n",
       "      <td>-0.267246</td>\n",
       "      <td>-0.088104</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.098431</td>\n",
       "      <td>0.114461</td>\n",
       "      <td>-0.061277</td>\n",
       "      <td>0.082030</td>\n",
       "      <td>-0.193377</td>\n",
       "      <td>-0.207277</td>\n",
       "      <td>-0.190424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328484</td>\n",
       "      <td>0.287683</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>-0.042790</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>-0.045144</td>\n",
       "      <td>-0.059807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_R</th>\n",
       "      <td>-0.811654</td>\n",
       "      <td>-0.222558</td>\n",
       "      <td>0.242574</td>\n",
       "      <td>-0.059658</td>\n",
       "      <td>0.072339</td>\n",
       "      <td>-0.046734</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>-0.747055</td>\n",
       "      <td>-0.780415</td>\n",
       "      <td>-0.712983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828517</td>\n",
       "      <td>0.328484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625298</td>\n",
       "      <td>-0.036586</td>\n",
       "      <td>-0.038528</td>\n",
       "      <td>-0.034757</td>\n",
       "      <td>-0.036525</td>\n",
       "      <td>-0.036146</td>\n",
       "      <td>-0.050254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_U</th>\n",
       "      <td>-0.522635</td>\n",
       "      <td>-0.186449</td>\n",
       "      <td>0.082371</td>\n",
       "      <td>-0.061530</td>\n",
       "      <td>0.069085</td>\n",
       "      <td>-0.053895</td>\n",
       "      <td>0.024438</td>\n",
       "      <td>-0.475716</td>\n",
       "      <td>-0.474077</td>\n",
       "      <td>-0.431286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486007</td>\n",
       "      <td>0.287683</td>\n",
       "      <td>0.625298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>-0.034914</td>\n",
       "      <td>-0.032509</td>\n",
       "      <td>-0.032741</td>\n",
       "      <td>-0.039332</td>\n",
       "      <td>-0.048426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_R</th>\n",
       "      <td>0.037025</td>\n",
       "      <td>0.022260</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.081903</td>\n",
       "      <td>-0.071170</td>\n",
       "      <td>0.165985</td>\n",
       "      <td>-0.195818</td>\n",
       "      <td>0.025570</td>\n",
       "      <td>0.023738</td>\n",
       "      <td>0.020043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027471</td>\n",
       "      <td>-0.043091</td>\n",
       "      <td>-0.036586</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197202</td>\n",
       "      <td>0.226058</td>\n",
       "      <td>0.169282</td>\n",
       "      <td>0.236631</td>\n",
       "      <td>0.294454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_R</th>\n",
       "      <td>0.038832</td>\n",
       "      <td>0.023401</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.206301</td>\n",
       "      <td>-0.212356</td>\n",
       "      <td>0.243502</td>\n",
       "      <td>-0.290289</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.025622</td>\n",
       "      <td>0.021706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031283</td>\n",
       "      <td>-0.045653</td>\n",
       "      <td>-0.038528</td>\n",
       "      <td>-0.034914</td>\n",
       "      <td>0.197202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360994</td>\n",
       "      <td>0.260784</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.422787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_R</th>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.188231</td>\n",
       "      <td>-0.187838</td>\n",
       "      <td>0.258829</td>\n",
       "      <td>-0.301351</td>\n",
       "      <td>0.026626</td>\n",
       "      <td>0.024808</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029904</td>\n",
       "      <td>-0.042790</td>\n",
       "      <td>-0.034757</td>\n",
       "      <td>-0.032509</td>\n",
       "      <td>0.226058</td>\n",
       "      <td>0.360994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.273024</td>\n",
       "      <td>0.416287</td>\n",
       "      <td>0.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ToR</th>\n",
       "      <td>0.037687</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.182724</td>\n",
       "      <td>-0.185484</td>\n",
       "      <td>0.171197</td>\n",
       "      <td>-0.211739</td>\n",
       "      <td>0.026879</td>\n",
       "      <td>0.024641</td>\n",
       "      <td>0.021230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027742</td>\n",
       "      <td>-0.044878</td>\n",
       "      <td>-0.036525</td>\n",
       "      <td>-0.032741</td>\n",
       "      <td>0.169282</td>\n",
       "      <td>0.260784</td>\n",
       "      <td>0.273024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288827</td>\n",
       "      <td>0.331009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ts_R</th>\n",
       "      <td>0.037157</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.192329</td>\n",
       "      <td>-0.195101</td>\n",
       "      <td>0.266919</td>\n",
       "      <td>-0.314897</td>\n",
       "      <td>0.026505</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026310</td>\n",
       "      <td>-0.045144</td>\n",
       "      <td>-0.036146</td>\n",
       "      <td>-0.039332</td>\n",
       "      <td>0.236631</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.416287</td>\n",
       "      <td>0.288827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V75PROC</th>\n",
       "      <td>0.056450</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.418248</td>\n",
       "      <td>-0.372038</td>\n",
       "      <td>0.519214</td>\n",
       "      <td>-0.470052</td>\n",
       "      <td>0.039777</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040442</td>\n",
       "      <td>-0.059807</td>\n",
       "      <td>-0.050254</td>\n",
       "      <td>-0.048426</td>\n",
       "      <td>0.294454</td>\n",
       "      <td>0.422787</td>\n",
       "      <td>0.421761</td>\n",
       "      <td>0.331009</td>\n",
       "      <td>0.422505</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VLP      SVLP     VSVLP   VPN_SUM  VPN_SUM_ORD   VPK_SUM  \\\n",
       "VLP          1.000000 -0.071263 -0.367367  0.060885    -0.067348  0.042802   \n",
       "SVLP        -0.071263  1.000000  0.169084  0.038347    -0.042245  0.035518   \n",
       "VSVLP       -0.367367  0.169084  1.000000  0.013101    -0.015119  0.017971   \n",
       "VPN_SUM      0.060885  0.038347  0.013101  1.000000    -0.896917  0.209983   \n",
       "VPN_SUM_ORD -0.067348 -0.042245 -0.015119 -0.896917     1.000000 -0.190501   \n",
       "VPK_SUM      0.042802  0.035518  0.017971  0.209983    -0.190501  1.000000   \n",
       "VPK_SUM_ORD  0.001102 -0.029882 -0.037124 -0.197619     0.196000 -0.735108   \n",
       "VLPB         0.960169 -0.139038 -0.368311  0.040302    -0.045149  0.027460   \n",
       "SVLPB        0.969106 -0.180037 -0.442444  0.038096    -0.042867  0.024711   \n",
       "VSVLPB       0.944690 -0.299864 -0.404693  0.032319    -0.036507  0.019672   \n",
       "E_P          0.976880 -0.078638 -0.379678  0.048694    -0.054412  0.034336   \n",
       "E_P_Num     -0.757096 -0.111790  0.342066 -0.043809     0.053661 -0.032890   \n",
       "E_N         -0.267246 -0.088104 -0.001434 -0.098431     0.114461 -0.061277   \n",
       "E_R         -0.811654 -0.222558  0.242574 -0.059658     0.072339 -0.046734   \n",
       "E_U         -0.522635 -0.186449  0.082371 -0.061530     0.069085 -0.053895   \n",
       "G_R          0.037025  0.022260  0.003071  0.081903    -0.071170  0.165985   \n",
       "A_R          0.038832  0.023401  0.005808  0.206301    -0.212356  0.243502   \n",
       "T_R          0.037757  0.023214  0.008526  0.188231    -0.187838  0.258829   \n",
       "ToR          0.037687  0.020612  0.004987  0.182724    -0.185484  0.171197   \n",
       "Ts_R         0.037157  0.018145  0.000611  0.192329    -0.195101  0.266919   \n",
       "V75PROC      0.056450  0.030145  0.007657  0.418248    -0.372038  0.519214   \n",
       "\n",
       "             VPK_SUM_ORD      VLPB     SVLPB    VSVLPB    ...      E_P_Num  \\\n",
       "VLP             0.001102  0.960169  0.969106  0.944690    ...    -0.757096   \n",
       "SVLP           -0.029882 -0.139038 -0.180037 -0.299864    ...    -0.111790   \n",
       "VSVLP          -0.037124 -0.368311 -0.442444 -0.404693    ...     0.342066   \n",
       "VPN_SUM        -0.197619  0.040302  0.038096  0.032319    ...    -0.043809   \n",
       "VPN_SUM_ORD     0.196000 -0.045149 -0.042867 -0.036507    ...     0.053661   \n",
       "VPK_SUM        -0.735108  0.027460  0.024711  0.019672    ...    -0.032890   \n",
       "VPK_SUM_ORD     1.000000  0.018456  0.021701  0.024180    ...    -0.004979   \n",
       "VLPB            0.018456  1.000000  0.971581  0.961246    ...    -0.682341   \n",
       "SVLPB           0.021701  0.971581  1.000000  0.988131    ...    -0.759554   \n",
       "VSVLPB          0.024180  0.961246  0.988131  1.000000    ...    -0.700718   \n",
       "E_P             0.013088  0.962856  0.988286  0.963110    ...    -0.806287   \n",
       "E_P_Num        -0.004979 -0.682341 -0.759554 -0.700718    ...     1.000000   \n",
       "E_N             0.082030 -0.193377 -0.207277 -0.190424    ...     0.237266   \n",
       "E_R             0.005976 -0.747055 -0.780415 -0.712983    ...     0.828517   \n",
       "E_U             0.024438 -0.475716 -0.474077 -0.431286    ...     0.486007   \n",
       "G_R            -0.195818  0.025570  0.023738  0.020043    ...    -0.027471   \n",
       "A_R            -0.290289  0.026872  0.025622  0.021706    ...    -0.031283   \n",
       "T_R            -0.301351  0.026626  0.024808  0.021163    ...    -0.029904   \n",
       "ToR            -0.211739  0.026879  0.024641  0.021230    ...    -0.027742   \n",
       "Ts_R           -0.314897  0.026505  0.025401  0.022150    ...    -0.026310   \n",
       "V75PROC        -0.470052  0.039777  0.036953  0.032059    ...    -0.040442   \n",
       "\n",
       "                  E_N       E_R       E_U       G_R       A_R       T_R  \\\n",
       "VLP         -0.267246 -0.811654 -0.522635  0.037025  0.038832  0.037757   \n",
       "SVLP        -0.088104 -0.222558 -0.186449  0.022260  0.023401  0.023214   \n",
       "VSVLP       -0.001434  0.242574  0.082371  0.003071  0.005808  0.008526   \n",
       "VPN_SUM     -0.098431 -0.059658 -0.061530  0.081903  0.206301  0.188231   \n",
       "VPN_SUM_ORD  0.114461  0.072339  0.069085 -0.071170 -0.212356 -0.187838   \n",
       "VPK_SUM     -0.061277 -0.046734 -0.053895  0.165985  0.243502  0.258829   \n",
       "VPK_SUM_ORD  0.082030  0.005976  0.024438 -0.195818 -0.290289 -0.301351   \n",
       "VLPB        -0.193377 -0.747055 -0.475716  0.025570  0.026872  0.026626   \n",
       "SVLPB       -0.207277 -0.780415 -0.474077  0.023738  0.025622  0.024808   \n",
       "VSVLPB      -0.190424 -0.712983 -0.431286  0.020043  0.021706  0.021163   \n",
       "E_P         -0.236096 -0.828605 -0.518892  0.028921  0.031676  0.031265   \n",
       "E_P_Num      0.237266  0.828517  0.486007 -0.027471 -0.031283 -0.029904   \n",
       "E_N          1.000000  0.328484  0.287683 -0.043091 -0.045653 -0.042790   \n",
       "E_R          0.328484  1.000000  0.625298 -0.036586 -0.038528 -0.034757   \n",
       "E_U          0.287683  0.625298  1.000000 -0.032172 -0.034914 -0.032509   \n",
       "G_R         -0.043091 -0.036586 -0.032172  1.000000  0.197202  0.226058   \n",
       "A_R         -0.045653 -0.038528 -0.034914  0.197202  1.000000  0.360994   \n",
       "T_R         -0.042790 -0.034757 -0.032509  0.226058  0.360994  1.000000   \n",
       "ToR         -0.044878 -0.036525 -0.032741  0.169282  0.260784  0.273024   \n",
       "Ts_R        -0.045144 -0.036146 -0.039332  0.236631  0.400400  0.416287   \n",
       "V75PROC     -0.059807 -0.050254 -0.048426  0.294454  0.422787  0.421761   \n",
       "\n",
       "                  ToR      Ts_R   V75PROC  \n",
       "VLP          0.037687  0.037157  0.056450  \n",
       "SVLP         0.020612  0.018145  0.030145  \n",
       "VSVLP        0.004987  0.000611  0.007657  \n",
       "VPN_SUM      0.182724  0.192329  0.418248  \n",
       "VPN_SUM_ORD -0.185484 -0.195101 -0.372038  \n",
       "VPK_SUM      0.171197  0.266919  0.519214  \n",
       "VPK_SUM_ORD -0.211739 -0.314897 -0.470052  \n",
       "VLPB         0.026879  0.026505  0.039777  \n",
       "SVLPB        0.024641  0.025401  0.036953  \n",
       "VSVLPB       0.021230  0.022150  0.032059  \n",
       "E_P          0.029775  0.029124  0.045251  \n",
       "E_P_Num     -0.027742 -0.026310 -0.040442  \n",
       "E_N         -0.044878 -0.045144 -0.059807  \n",
       "E_R         -0.036525 -0.036146 -0.050254  \n",
       "E_U         -0.032741 -0.039332 -0.048426  \n",
       "G_R          0.169282  0.236631  0.294454  \n",
       "A_R          0.260784  0.400400  0.422787  \n",
       "T_R          0.273024  0.416287  0.421761  \n",
       "ToR          1.000000  0.288827  0.331009  \n",
       "Ts_R         0.288827  1.000000  0.422505  \n",
       "V75PROC      0.331009  0.422505  1.000000  \n",
       "\n",
       "[21 rows x 21 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V75PROC        1.000000\n",
       "VPK_SUM        0.519214\n",
       "A_R            0.422787\n",
       "Ts_R           0.422505\n",
       "T_R            0.421761\n",
       "VPN_SUM        0.418248\n",
       "ToR            0.331009\n",
       "G_R            0.294454\n",
       "VLP            0.056450\n",
       "E_P            0.045251\n",
       "VLPB           0.039777\n",
       "SVLPB          0.036953\n",
       "VSVLPB         0.032059\n",
       "SVLP           0.030145\n",
       "VSVLP          0.007657\n",
       "E_P_Num       -0.040442\n",
       "E_U           -0.048426\n",
       "E_R           -0.050254\n",
       "E_N           -0.059807\n",
       "VPN_SUM_ORD   -0.372038\n",
       "VPK_SUM_ORD   -0.470052\n",
       "Name: V75PROC, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['V75PROC'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu plockar vi ut 52 (20%) v75 omgångar för att använda dem som test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v75 = df1.Datum.drop_duplicates().to_frame()\n",
    "\n",
    "v75['is_test']=np.random.uniform(0,1,len(v75))<=0.2\n",
    "\n",
    "test, basedf = v75[v75['is_test']==True], v75[v75['is_test']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(basedf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu bygger vi upp en pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "# Denna klass måste vi göra för att särskilja numeriska variabler mot character variabler\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egen klass för att sätta dummyvariabler\n",
    "\n",
    "class SetDummyVar(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        tempdf = pd.get_dummies(X[self.attribute_names], columns = self.attribute_names)\n",
    "        return tempdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline för numeriska variabler\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('dummy_cat', SetDummyVar(cat_attribs)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to avoid overfitting data is split into training data and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plockar in imgångarna vi ska träna modellen på\n",
    "train = df1[df1.Datum.isin(basedf.Datum.tolist())]\n",
    "\n",
    "# De 52 vi utvärderar på \n",
    "validate = df1[df1.Datum.isin(test.Datum.tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu skapar vi arrayer som ska användas av modellen - använder den skapade Pipelineobjektet som gör alla nödvändiga dataransformationer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Träningssdata\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_train = full_pipeline.fit_transform(train)\n",
    "## En array som håller det vi vill predikter\n",
    "label_train = train[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valideringsdata\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_validate = full_pipeline.fit_transform(validate)\n",
    "## En array som håller det vi vill predikter\n",
    "label_validate = validate[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimerar modell med gridsearch. Tar fram den slutliga modellen som vi sedan validerar mot de undanllagda 52 omgångarna__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [500],\n",
    "    'max_leaf_nodes':[16],\n",
    "    'max_features': ['sqrt', 'auto','log2'],\n",
    "    'criterion': ['gini'],\n",
    "    'bootstrap': [True, False],\n",
    "    'n_jobs':[-1]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [500], 'max_leaf_nodes': [16], 'max_features': ['sqrt', 'auto', 'log2'], 'criterion': ['gini'], 'bootstrap': [True, False], 'n_jobs': [-1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skapar instansen av modellen\n",
    "rf_all = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(rf_all, param_grid, cv=5, scoring = 'roc_auc' , return_train_score=True)\n",
    "grid_search.fit(features_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': 16,\n",
       " 'n_estimators': 500,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pararg = grid_search.best_params_\n",
    "pararg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**pararg)\n",
    "scores_opt = cross_val_score(rf, features_train, label_train , scoring = \"roc_auc\", cv = 5 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79554975, 0.75568216, 0.78921778, 0.81275501, 0.79504501])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7896499395346523"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='log2', max_leaf_nodes=16,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bygger den slutliga modellen\n",
    "rf.fit(features_train,label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu itererar vi över alla testloppen. Plockar de 24 högsta scorade hästarna__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Om det finns omgångar där någon feature enbart håller missing plockas dessa bort ==> Kan inte scoras.\n",
    "# Bygger logik som checkar det på de numeriska variablerna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive\n",
    "tp_list = []\n",
    "# False positive\n",
    "fp_list = []\n",
    "d_list = validate.Datum.drop_duplicates().tolist()\n",
    "for date in d_list:\n",
    "    df_test1 = validate[validate.Datum == date].drop('Datum', axis = 1)\n",
    "    features_test = full_pipeline.fit_transform(df_test1)\n",
    "    label_test = df_test1[\"Y\"].copy()\n",
    "    predict_test = rf.predict_proba(features_test)\n",
    "    \n",
    "    predict_cutoff = pd.DataFrame({'Prob0':predict_test[:,0],'Prob1':predict_test[:,1]}).sort_values('Prob1', ascending = False).iloc[30]['Prob1']\n",
    "    \n",
    "    y_pred_test = np.where( predict_test[:,1] > predict_cutoff,1,0)\n",
    "    #print(confusion_matrix(label_test, y_pred_test),date)\n",
    "    # Stoppar in i lista - True positive\n",
    "    tp_list.append(confusion_matrix(label_test, y_pred_test)[1][1])\n",
    "    # Stoppar in i lista - False positive\n",
    "    fp_list.append(confusion_matrix(label_test, y_pred_test)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.333333333333333"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_tp = 0\n",
    "sum_fp = 0\n",
    "sum_tot = 0\n",
    "for tp, fp in zip(tp_list, fp_list):\n",
    "    sum_tp = sum_tp + tp\n",
    "    sum_fp = sum_fp + fp\n",
    "    sum_tot = sum_tot + tp + fp\n",
    "\n",
    "avg_tp = sum_tp / len(tp_list)\n",
    "avg_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medelantal hästar ut\n",
    "avg_out = sum_tot / len(tp_list)\n",
    "avg_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17777777777777776"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "avg_tp/avg_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar fram diagram på fördelningen. True-Positive\n",
    "# Gör en dataframe för att sedan gruppera\n",
    "\n",
    "tp = {'TP':tp_list}\n",
    "\n",
    "tp_frame = pd.DataFrame.from_dict(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "koll = round(tp_frame.TP.value_counts().sort_index()/len(test)*100,1)\n",
    "koll.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     2.4\n",
       "3     2.4\n",
       "4    16.7\n",
       "5    31.0\n",
       "6    33.3\n",
       "7    14.3\n",
       "Name: TP, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "koll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure DistRes25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1) = plt.subplots(1, 1, figsize=(12,8))\n",
    "\n",
    "ax1.bar(koll.index.tolist(), koll, color=(0.2, 0.4, 0.6, 1))\n",
    "\n",
    "for x, y in zip(koll.index.tolist(), koll):\n",
    "    ax1.text(x,y+0.5,str(int(round(y)))+'%', ha = 'center', fontsize=14)\n",
    "    \n",
    "ax1.set_title('Procentuell Fördelning resultat-Utvärderat på 38 omgångar - 25 hästar uttagna i varje omgång')\n",
    "\n",
    "ax1.set_ybound(0,50)\n",
    "\n",
    "save_fig('DistRes25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__På VNUM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list = []\n",
    "b_list = []\n",
    "d_list = validate.Datum.drop_duplicates().tolist()\n",
    "for date in d_list:\n",
    "    df_test1 = validate[validate.Datum == date].drop('Datum', axis = 1)\n",
    "    df_test1['Pred'] = np.where(df_test1.VNUM.isin([1,2,3,4]),1,0)\n",
    "    df_test1['Facit'] =  np.where((df_test1.Pred == 1) & (df_test1.Y == 1) ,1,0)\n",
    "    cm_list.append(df_test1.Facit.sum())\n",
    "    b_list.append(df_test1.Pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.476190476190476"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tp_tot = 0\n",
    "out_tot = 0\n",
    "for tp, tot in zip(cm_list,b_list):\n",
    "    tp_tot = tp_tot + tp\n",
    "    out_tot = out_tot + tot\n",
    "\n",
    "avg = tp_tot / len(cm_list)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_out_tot = out_tot/len(cm_list) \n",
    "avg_out_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.195578231292517"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "avg/avg_out_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu plockar vi de fyra högst scorade hästarna i varje lopp__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(df):\n",
    "    return df.sort_values(['Lopp','Prob1'], ascending = [True, False])[['Prob1','Lopp','Y']].iloc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = validate.Datum.drop_duplicates().tolist()\n",
    "res_list = []\n",
    "for date in d_list:\n",
    "    df_test1 = validate[validate.Datum == date].drop('Datum', axis = 1)\n",
    "    df_test1['GRUPP'] = df_test1.GRUPP.astype('object')\n",
    "    features = full_pipeline.fit_transform(df_test1)\n",
    "    predict = rf.predict_proba(features)\n",
    "    predict_frame = pd.DataFrame({'Prob0':predict[:,0],'Prob1':predict[:,1]})\n",
    "    df_lopp = predict_frame.merge(df_test1.reset_index(), right_index = True, left_index = True)\n",
    "    grouped = df_lopp.groupby('Lopp')\n",
    "    result = grouped.apply(top).Y.sum()\n",
    "    res_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.447368421052632"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot = 0\n",
    "for res in res_list:\n",
    "    tot +=res\n",
    "avg = tot/len(res_list)\n",
    "avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu bygger vi en modell på hela datamängden med de optimerade hyperparametrarna och utvärderer med cross fold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = full_pipeline.fit_transform(df1)\n",
    "## En array som håller det vi vill predikter\n",
    "label = df1[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final_model = RandomForestClassifier(**pararg)\n",
    "scores_opt = cross_val_score(rf_final_model, features, label, scoring = \"roc_auc\", cv = 5 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8102234 , 0.75579674, 0.78378755, 0.81452813, 0.78904586])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7906763350634878"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='log2', max_leaf_nodes=16,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bygger den slutliga modellen\n",
    "rf_final_model.fit(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Travmodel_v5.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Pipelineobjekt\n",
    "joblib.dump(full_pipeline, 'Pipeline_v5.pkl')\n",
    "\n",
    "# Modellobjekt\n",
    "joblib.dump(rf_final_model, 'Travmodel_v5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
