{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Första modellutkast - Random Forrest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Sklearn objects used in the analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('DataV75TillUffe_2019-02-01_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17994 entries, 0 to 17993\n",
      "Data columns (total 38 columns):\n",
      "Datum          17994 non-null datetime64[ns]\n",
      "Utdelning      17994 non-null int64\n",
      "Arstid         17994 non-null int64\n",
      "Distans        17994 non-null int64\n",
      "Startsatt      17994 non-null int64\n",
      "Lopp           17994 non-null int64\n",
      "Plac           17994 non-null int64\n",
      "Hast           17994 non-null int64\n",
      "V75PROC        17994 non-null float64\n",
      "V_ODDS         17994 non-null float64\n",
      "GRUPP          17994 non-null int64\n",
      "VLP            17994 non-null float64\n",
      "VNUM           17994 non-null int64\n",
      "SVLP           17994 non-null float64\n",
      "VSVLP          17994 non-null float64\n",
      "VPN_SUM        17994 non-null float64\n",
      "VPN_SUM_ORD    17994 non-null int64\n",
      "VPK_SUM        17994 non-null float64\n",
      "VPK_SUM_ORD    17994 non-null int64\n",
      "VLPB           17994 non-null float64\n",
      "SVLPB          17994 non-null float64\n",
      "VSVLPB         17994 non-null float64\n",
      "E_P            17994 non-null float64\n",
      "E_P_Num        17994 non-null int64\n",
      "E_N            17994 non-null float64\n",
      "E_R            17994 non-null float64\n",
      "E_U            17994 non-null float64\n",
      "G_R            16243 non-null float64\n",
      "S_R            15358 non-null float64\n",
      "A_R            15310 non-null float64\n",
      "T_R            16317 non-null float64\n",
      "SP_R           4730 non-null float64\n",
      "ToR            15201 non-null float64\n",
      "P_R            15903 non-null float64\n",
      "TK_R           10225 non-null float64\n",
      "Ex_R           9979 non-null float64\n",
      "R_R            9979 non-null float64\n",
      "Ts_R           17994 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(24), int64(13)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16439\n",
       "1     1555\n",
       "Name: Plac, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Plac.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Datum.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "222*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en unik nyckel på lopp: Gör om Datum och lopp till en sträng\n",
    "\n",
    "df1['cdate'] = df1.Datum.astype('object')\n",
    "df1['cLopp'] = df1.Lopp.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Key'] = df1['cdate'].astype(str) + df1['cLopp'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17994"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Key.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Skapar en målvariabel - vinnare__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Y'] = np.where(df1['Plac'].isin([1]), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu plockar vi ut 10 v75 omgångar för att använda dem som test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "v75 = df1.Datum.drop_duplicates().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "v75['is_test']=np.random.uniform(0,1,len(v75))<=0.05\n",
    "\n",
    "test, basedf = v75[v75['is_test']==True], v75[v75['is_test']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Skapar en kopia, droppar de variabler som inte ska vara med i analysen samt sätter index__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17994 entries, 0 to 17993\n",
      "Data columns (total 42 columns):\n",
      "Datum          17994 non-null datetime64[ns]\n",
      "Utdelning      17994 non-null int64\n",
      "Arstid         17994 non-null int64\n",
      "Distans        17994 non-null int64\n",
      "Startsatt      17994 non-null int64\n",
      "Lopp           17994 non-null int64\n",
      "Plac           17994 non-null int64\n",
      "Hast           17994 non-null int64\n",
      "V75PROC        17994 non-null float64\n",
      "V_ODDS         17994 non-null float64\n",
      "GRUPP          17994 non-null int64\n",
      "VLP            17994 non-null float64\n",
      "VNUM           17994 non-null int64\n",
      "SVLP           17994 non-null float64\n",
      "VSVLP          17994 non-null float64\n",
      "VPN_SUM        17994 non-null float64\n",
      "VPN_SUM_ORD    17994 non-null int64\n",
      "VPK_SUM        17994 non-null float64\n",
      "VPK_SUM_ORD    17994 non-null int64\n",
      "VLPB           17994 non-null float64\n",
      "SVLPB          17994 non-null float64\n",
      "VSVLPB         17994 non-null float64\n",
      "E_P            17994 non-null float64\n",
      "E_P_Num        17994 non-null int64\n",
      "E_N            17994 non-null float64\n",
      "E_R            17994 non-null float64\n",
      "E_U            17994 non-null float64\n",
      "G_R            16243 non-null float64\n",
      "S_R            15358 non-null float64\n",
      "A_R            15310 non-null float64\n",
      "T_R            16317 non-null float64\n",
      "SP_R           4730 non-null float64\n",
      "ToR            15201 non-null float64\n",
      "P_R            15903 non-null float64\n",
      "TK_R           10225 non-null float64\n",
      "Ex_R           9979 non-null float64\n",
      "R_R            9979 non-null float64\n",
      "Ts_R           17994 non-null int64\n",
      "cdate          17994 non-null object\n",
      "cLopp          17994 non-null object\n",
      "Key            17994 non-null object\n",
      "Y              17994 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(24), int64(14), object(3)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[(df1.Datum > '2016-05-20') & (df1.Datum.isin(basedf.Datum.tolist()))]. \\\n",
    "drop(['Utdelning','Datum','Arstid','Distans','Startsatt','Lopp','Plac','Hast','cdate','cLopp','VNUM','V_ODDS','S_R', \\\n",
    "      'V75PROC'], axis = 1). \\\n",
    "copy().set_index(['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df =  df1[(df1.Datum > '2016-05-20') & (df1.Datum.isin(test.Datum.tolist()))]. \\\n",
    "drop(['Utdelning','Arstid','Distans','Startsatt','Lopp','Plac','Hast','cdate','cLopp','VNUM','V_ODDS','S_R', \\\n",
    "      'V75PROC'], axis = 1). \\\n",
    "copy().set_index(['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16953"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gör om GRUPP till objekt för att kunna använda befintlig dummylogik__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'GRUPP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-314-41a1110b2b5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GRUPP'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRUPP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'GRUPP'"
     ]
    }
   ],
   "source": [
    "df2['GRUPP'] = df2.GRUPP.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Delar upp i numeriska samt charachter attribut. Det är dessa som går in i modellen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = []\n",
    "cat_attribs = []\n",
    "for var, typ in zip(df2.columns[:-1], df2.dtypes[:-1]):\n",
    "    if typ == 'object':\n",
    "        cat_attribs.append(var)\n",
    "    else:\n",
    "        num_attribs.append(var)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "tempdf = pd.get_dummies(df1.GRUPP)\n",
    "for val in tempdf.columns:\n",
    "    name_list.append('GRUPP'+str(val))\n",
    "        \n",
    "name_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = num_attribs + name_list\n",
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu bygger vi upp en pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "# Denna klass måste vi göra för att särskilja numeriska variabler mot character variabler\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egen klass för att sätta dummyvariabler\n",
    "\n",
    "class SetDummyVar(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        tempdf = pd.get_dummies(X[self.attribute_names], columns = self.attribute_names)\n",
    "        return tempdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline för numeriska variabler\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('dummy_cat', SetDummyVar(cat_attribs)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to avoid overfitting data is split into training data and validation data. 75% träningsdata och 25% valideringsdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['is_train']=np.random.uniform(0,1,len(df2))<=0.75\n",
    "\n",
    "train, validate = df2[df2['is_train']==True], df2[df2['is_train']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu skapar vi arrayer som ska användas av modellen - använder den skapade Pipelineobjektet som gör alla nödvändiga dataransformationer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Träningssdata\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_train = full_pipeline.fit_transform(train)\n",
    "## En array som håller det vi vill predikter\n",
    "label_train = train[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valideringsdata\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_validate = full_pipeline.fit_transform(validate)\n",
    "## En array som håller det vi vill predikter\n",
    "label_validate = validate[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the training data and then evaluate on the validation data\n",
    "\n",
    "- predicts: A twodimensional array that contains posterrior probabbility for a donation behaviour, one for non-donation and one for donation\n",
    "- fpr : False positive rate, number of false positive for a specific threshold value\n",
    "- tpr : True positive rate, number of true positive for a specific threshold value\n",
    "- threshold: Sorted threshold (descending) values for the likelihod to donate\n",
    "- roc_auc: Receiver operating characteristics. A value close to 1 indicates a strong model. A value close to 0.5 means that the model is rather poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bygger random forrest och analyserar roc_auc\n",
    "# Instansierar modellen\n",
    "rf = RandomForestClassifier(n_estimators = 1000, max_depth=5)\n",
    "\n",
    "# Tränar modellen\n",
    "\n",
    "rf.fit(features_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "for name, weight in zip(features_list, rf.feature_importances_):\n",
    "    weight_dict = {'Feature': name, 'Weight': weight}\n",
    "    weight_list.append(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analys_weight = pd.DataFrame(weight_list).sort_values('Weight', ascending = False)\n",
    "\n",
    "analys_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analys_weight.to_excel('Weight.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predikterar med modellen med valideringsdata\n",
    "\n",
    "predict = rf.predict_proba(features_validate)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(label_validate,predict[:,1])\n",
    "\n",
    "roc_auc = auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_ser = pd.Series(fpr)\n",
    "tpr_ser = pd.Series(tpr)\n",
    "threshold_ser = pd.Series(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Vi gör en dataframe av fpr, tpr, threshold för att förstå relationerna__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exempel\n",
    "df = pd.concat([fpr_ser, tpr_ser,threshold_ser], axis=1).rename(columns = {0: 'fpr', 1:'tpr',2:'threshold'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median värde för den sannolikhet som genereras på varje enskild observation\n",
    "prob = pd.Series(predict[:,1])\n",
    "prob.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(14,8), linewidth=5, edgecolor='.5')\n",
    "\n",
    "\n",
    "ax1.hist(prob, bins = 50)\n",
    "ax2.hist(threshold, bins = 50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.threshold.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Varför ger threshold och prob olika medianvärden?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A ROC curve for the charity classifier on the charity data\n",
    "\n",
    "__It traces out two types of error as we vary the threshold value for the posterior probability of charity. The actual thresholds are not shown. The true positive rate is the sensitivity: the fraction of givers that are correctly identified, using a given threshold value. The false positive rate is 1-specificity: the fraction of non-givers that we classify incorrectly as givers, using that same threshold value. The ideal ROC curve hugs the top left corner, indicating a high true positive rate and a low false positive rate. The dotted line represents the “no information” classifier.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graf\n",
    "\n",
    "plt.title('Receiver Operating Characteristic') \n",
    "plt.plot( fpr, tpr, 'b', label =' AUC = %0.3f' % roc_auc) \n",
    "plt.legend( loc ='lower right') \n",
    "plt.plot([ 0, 1], [0, 1], 'r--') \n",
    "plt.xlim([ 0.0, 1.0]) \n",
    "plt.ylim([ 0.0, 1.0]) \n",
    "plt.ylabel('True positive rate') \n",
    "plt.xlabel('False positive rate') \n",
    "save_fig('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(label_validate, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.xlim([0, 1])\n",
    "save_fig(\"precision_recall_vs_threshold_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "y_truth = label_validate\n",
    "confusion_matrix(label_validate, y_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.threshold.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi väljer medianvärdet som cut off \n",
    "y_pred = np.where( prob > prob.median(),1,0)\n",
    " \n",
    "confusion_matrix(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "346 / (1764 + 346)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision - Av de vi predikterar som vinnare, hur bra är vi\n",
    "precision_score(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive rate = Den totala andelen av sanna postiva vid en given cut of\n",
    "recall_score(label_validate, y_pred)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_validate_ser = pd.Series(label_validate.tolist())\n",
    "prob_ser = pd.Series(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.concat([label_validate_ser, prob_ser], axis = 1).rename(columns = {0:'Y',1 :'Prob'}). \\\n",
    "sort_values('Prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Delar in i deciler på den framräknade scoren__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_valid.Prob.values\n",
    "quartiles = pd.qcut(data, 10)\n",
    "pd.value_counts(quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_valid.Y.groupby(quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Beräknar den procentuella andelen vinnare i respektice decil__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = round((grouped.sum() / grouped.count() * 100))\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16,12))\n",
    "\n",
    "#df2[['VLP']].hist(bins=50, ax = ax1, label = 'Variansen på V75PROC - VLP')\n",
    "\n",
    "df_valid.Prob.plot(kind = 'hist', bins = 100, title = 'Probability response', ax = ax1)\n",
    "\n",
    "\n",
    "resp.plot(kind = 'bar', color=(0.2, 0.4, 0.6, 1),title = 'Andel vinnare per decil', ax = ax2)\n",
    "\n",
    "save_fig('Probdist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(prob >=0.174,1,0)\n",
    " \n",
    "confusion_matrix(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "precision_score(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive rate = Den totala andelen av sanna postiva vid en given cut of\n",
    "recall_score(label_validate, y_pred)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(prob >=0.131,1,0)\n",
    " \n",
    "confusion_matrix(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True positive rate = Den totala andelen av sanna postiva vid en given cut of\n",
    "recall_score(label_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I df ligger roc statistiken. Plockar ut raden där 0.75 < tpr < 0.8. Vad är threshols\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = df.tpr > 0.60\n",
    "f2 = df.tpr < 0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[f1 & f2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu har vi modellen. Nu vill vi testa på våra undanlagda 9 omgångar för att se hur det lirar. Skapar testdatasetet och kör sedan igenom varje omgång. Flaggar upp alla över score 0.135 som vinnar och räknar sedan ut hur det fallit ut__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.Datum.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df.Datum == '2018-11-25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plockar ut en omgång och scorar denna \n",
    "\n",
    "df_test1 = test_df[test_df.Datum == '2018-11-25'].drop('Datum', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1['GRUPP'] = df_test1.GRUPP.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1.Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdata som modllen ska scoras på\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_test = full_pipeline.fit_transform(df_test1)\n",
    "## En array som håller det vi vill predikter\n",
    "label_test = df_test1[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = rf.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = np.where( predict_test[:,1] > 0.135,1,0)\n",
    " \n",
    "confusion_matrix(label_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = np.where( predict_test[:,1] > 0.184,1,0)\n",
    " \n",
    "confusion_matrix(label_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu itererar vi över alla testloppen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validering(Date):\n",
    "    df_test1 = test_df[test_df.Datum == Date].drop('Datum', axis = 1)\n",
    "    df_test1['GRUPP'] = df_test1.GRUPP.astype('object')\n",
    "    features_test = full_pipeline.fit_transform(df_test1)\n",
    "    label_test = df_test1[\"Y\"].copy()\n",
    "    predict_test = rf.predict_proba(features_test)\n",
    "    y_pred_test = np.where( predict_test[:,1] > 0.135,1,0)\n",
    "    confusion_matrix(label_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = test_df.Datum.drop_duplicates().to_frame().reset_index()\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = ['2017-08-16','2017-08-23','2018-11-11','2018-11-25']\n",
    "for date in d_list:\n",
    "    df_test1 = test_df[test_df.Datum == date].drop('Datum', axis = 1)\n",
    "    df_test1['GRUPP'] = df_test1.GRUPP.astype('object')\n",
    "    features_test = full_pipeline.fit_transform(df_test1)\n",
    "    label_test = df_test1[\"Y\"].copy()\n",
    "    predict_test = rf.predict_proba(features_test)\n",
    "    y_pred_test = np.where( predict_test[:,1] > 0.135,1,0)\n",
    "    print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = ['2017-08-16','2017-08-23','2018-11-11','2018-11-25']\n",
    "for date in d_list:\n",
    "    df_test1 = test_df[test_df.Datum == date].drop('Datum', axis = 1)\n",
    "    df_test1['GRUPP'] = df_test1.GRUPP.astype('object')\n",
    "    features_test = full_pipeline.fit_transform(df_test1)\n",
    "    label_test = df_test1[\"Y\"].copy()\n",
    "    predict_test = rf.predict_proba(features_test)\n",
    "    y_pred_test = np.where( predict_test[:,1] > 0.184,1,0)\n",
    "    print(confusion_matrix(label_test, y_pred_test),date)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testar Åby 20190202__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aby = pd.read_excel('Åby2019-02-02.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aby.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aby['Y'] = np.where(df_aby['Plac'].isin([1]), 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aby.Y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-02-02'\n",
    "df_aby['GRUPP'] = df_aby.GRUPP.astype('object')\n",
    "features_test = full_pipeline.fit_transform(df_aby)\n",
    "label_test = df_aby[\"Y\"].copy()\n",
    "predict_test = rf.predict_proba(features_test)\n",
    "y_pred_test = np.where( predict_test[:,1] > 0.131,1,0)\n",
    "print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-02-02'\n",
    "y_pred_test = np.where( predict_test[:,1] > 0.184,1,0)\n",
    "print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Axvalla 2019-02-16__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_axv = pd.read_excel('AxevallaDataV75TillUffe_2019-02-16.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_axv.Plac.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_axv['Y'] = np.where(df_axv['Plac'].isin([1]), 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-02-16'\n",
    "df_axv['GRUPP'] = df_axv.GRUPP.astype('object')\n",
    "features_test = full_pipeline.fit_transform(df_axv)\n",
    "label_test = df_axv[\"Y\"].copy()\n",
    "predict_test = rf.predict_proba(features_test)\n",
    "y_pred_test = np.where( predict_test[:,1] > 0.089,1,0)\n",
    "print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gör om scorad array till en lista - multidimensionell\n",
    "stack = predict_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sedan plockar vi den scorade sannolikheten att vara vinnare - 1\n",
    "# Transformerar denna sannolikhet till en dataframe\n",
    "last = []\n",
    "for x in stack:\n",
    "    last.append(x[1])\n",
    "scored = {'Score':last}\n",
    "# Konverterar till Dataframe\n",
    "df_scored = pd.DataFrame.from_dict(scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gör om till lista och stoppar in i ett dictionary\n",
    "pred = y_pred_test.tolist()\n",
    "prediction = {'Predict':pred}\n",
    "# Konverterar till Dataframe\n",
    "df_pred = pd.DataFrame.from_dict(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konkatierar mot urspringsdatat\n",
    "\n",
    "df_axv_predict = pd.concat([df_axv,df_pred, df_scored], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_axv_out = df_axv_predict[df_axv_predict.Predict == 1][['Lopp','Plac','Hast','Score']]. \\\n",
    "sort_values(['Lopp','Score'], ascending = [True,False])\n",
    "df_axv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-02-16'\n",
    "y_pred_test = np.where( predict_test[:,1] > 0.131,1,0)\n",
    "print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-02-16'\n",
    "y_pred_test = np.where( predict_test[:,1] > 0.184,1,0)\n",
    "print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sparar undan pipelineobjekt och modellobjekt för att kunna återanvänd senare__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelineobjekt\n",
    "joblib.dump(full_pipeline, 'Pipeline_v1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modellobjekt\n",
    "joblib.dump(rf, 'Travmodel_v1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu testar vi att läsa in modell- och pipelinebjekten__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_loaded = joblib.load('Travmodel_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline_loaded = joblib.load('Pipeline_v1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2019-02-02'\n",
    "df_aby['GRUPP'] = df_aby.GRUPP.astype('object')\n",
    "features_test = my_pipeline_loaded.fit_transform(df_aby)\n",
    "label_test = df_aby[\"Y\"].copy()\n",
    "predict_test = my_model_loaded.predict_proba(features_test)\n",
    "y_pred_test = np.where( predict_test[:,1] > 0.131,1,0)\n",
    "print(confusion_matrix(label_test, y_pred_test),date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nedan försöker vi optimera modellen med Gridsearch samt använder sig av hela datasetet med Cross validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allt data\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features = full_pipeline.fit_transform(df2)\n",
    "## En array som håller det vi vill predikter\n",
    "labels = df2[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_all = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(rf_all, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(features, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
