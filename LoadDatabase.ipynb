{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Detta steg förutsätter att kodboken är kontrollerad - CheckExcelfiles ska ha körts. Om det finns fel i mappningen så stannar Python där och detta steg får inte köras\n",
    "\n",
    "1. Läser in de nya excelfilerna i Pandas. \n",
    "2. Mappar mot kodboken. \n",
    "3. Skapar nödvändiga varibler \n",
    "4. Flyttar de inlästa excelfilerna till katalogen inlästa\n",
    "5. Skapar nya excelfiler från template\n",
    "6. Laddar databasen\n",
    "7. Sparar undan denna som ett pickle objekt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpath = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Börjar med att skapa en felhanteringsklass som används för att checka om aktuella datum redan laddats i databasen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Error(Exception):\n",
    " \n",
    "    # Error is derived class for Exception, but\n",
    "    # Base class for exceptions in this module\n",
    "    pass\n",
    "\n",
    "# Ett generiskt error som vi kan lägga in när vi behöver stänga Python\n",
    "class ValueError(Error):\n",
    "    def __init__(self, msg):\n",
    "        self.msg = msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Läser in de nya excelfilerna i Pandas -ligger på inputkatalogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Läser in excelfilerna i Pandas format, sparar i en lista\n",
    "df_list = []\n",
    "for folderName, subfolders, fileNames in os.walk(os.path.join(cpath,\"Input\")):\n",
    "    for name in fileNames:\n",
    "        df = pd.read_excel(os.path.join(folderName,name), sheet_name = 0)\n",
    "        if len(df[pd.isnull(df.Kanal) == True]):\n",
    "            raise(ValueError('Kanal saknar ett värde. Inputfil ' + name))\n",
    "        if len(df[pd.isnull(df.Nyhetskategori) == True]):\n",
    "            raise(ValueError('Nyhetskategori saknar ett värde. Inputfil ' + name))\n",
    "        \n",
    "        df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Läser in kodboken och skapar dictionary för mappning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kanal, senaste kodboken\n",
    "meta1_df = pd.read_excel(os.path.join(cpath,'kodbok', 'kodbok.xls'), sheet_name = 1)\n",
    "\n",
    "# Nyhetskategori\n",
    "meta2_df = pd.read_excel(os.path.join(cpath,'kodbok', 'kodbok.xls'), sheet_name = 4)\n",
    "\n",
    "mapping_kanal = meta1_df.set_index('kod')['kanal'].to_dict()\n",
    "mapping_nykat = meta2_df.set_index('kod')['kategori'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Beräkbar index, gör en funktion som skapar variabeln seg. Denna används sedan för att beräkna index\n",
    "### Skapar index på det nya måttet. Använder 3.56 som bas, medelvärde för segmentsvariabeln 2012 \n",
    "\n",
    "def segment(mfyll,impact):\n",
    "    if mfyll in [1,2,3] and impact in [5,6]:\n",
    "        seg = 1\n",
    "    elif mfyll in [1,2,3] and impact == 4:\n",
    "        seg = 2;\n",
    "    elif mfyll in [1,2,3] and impact in [1,2,3]:\n",
    "        seg = 3\n",
    "    elif mfyll in [4,5,6,7] and impact in [1,2,3]:\n",
    "        seg = 4\n",
    "    elif mfyll in [4] and impact in [4]:\n",
    "        seg = 5\n",
    "    elif mfyll in [5,6,7] and impact in [4]:\n",
    "        seg = 6\n",
    "    elif mfyll in [4,5,6,7] and impact in [5,6]:\n",
    "        seg = 7  \n",
    "    index = round((seg / 3.56) * 100) \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Läser in loaddate och skapar dictionary för mappning. Denna håller namn på de datum som ska läsas in__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egendefinierad dataframe med laddningsdatum och filnamn\n",
    "\n",
    "load_date_df = pd.read_pickle(\"load_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu skapar vi ett dictionary som kan användas för mappning \n",
    "mapping_vecka = load_date_df.set_index('Date')['vecka'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nu loopar vi igenom de inlästa pandas filerna och skapar de variabler som behöver läggas till\n",
    "### De transformerade dataframse läggs i en ny lista\n",
    "# Här måste vi lägga in vecka, hämta från metadata. Skapa ett dicionaru från metdata som håller datum:vecka och applicera \n",
    "# logiken nedan med en apply, lambda, map logik\n",
    "\n",
    "transformed_list = []\n",
    "i = -1\n",
    "for df in df_list:\n",
    "    i +=1\n",
    "    if df.iloc[0,0] != 0: #Tar bort de som inte har några rapporterade nyheter\n",
    "        df['nykat1'] = df['Nyhetskategori'].map(mapping_nykat)\n",
    "        df['kanal1'] = df['Kanal'].map(mapping_kanal)\n",
    "        df['date'] = pd.to_datetime('20'+fileNames[i][0:6])\n",
    "        df['vers'] = fileNames[i][7:9]\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['vecka'] = df['date'].map(mapping_vecka)\n",
    "\n",
    "        df = df.rename(columns = {'Måluppfyllelse' :'mfyll', 'Aktör': 'Akt_r', 'Rubrik':'rubrik',\n",
    "                                     'Nyhetskategori':'nykat', 'Medieslag': 'med'})\n",
    "        df['index'] = df.apply(lambda x : segment(x['mfyll'], x['Impact']), axis = 1)   \n",
    "        transformed_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Läser vi in existerande databasen från Pickles format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "databas = pd.read_pickle('Databas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nu ska vi appenda på de 12 filerna på databasen. Sedan kan rapporterna tas fram\n",
    "### Här måste vi lägga in en kontroll på att vi inte laddar in ett existerande datum\n",
    "### Då ska laddningen avbrytas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar ett set av alla de datum som är inlästa i databesen\n",
    "date_set = set()\n",
    "for date in databas.date:\n",
    "    date_set.add(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu gör vi en lista av de datum som ligger i inputfilerna\n",
    "\n",
    "input_date = list()\n",
    "for i in range(len(transformed_list)):\n",
    "    i_set = transformed_list[i].iloc[0].date\n",
    "    input_date.append(i_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu checkar vi varje datum med setet för redan laddade datum\n",
    "# Om True faller ut ska Python stängas ned, så att databasen inte laddas felaktigt\n",
    "\n",
    "for date in input_date:\n",
    "    if date in date_set:\n",
    "            raise(ValueError('Datumet har redan laddats i befintlig databas - inte tillåtet att ladda om'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Konkatinera filerna mot databasen - måste lägga databasen i en lista också__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konkatinerar varje fil på databasen\n",
    "# Lägger varje uppdaterad databas i en egen lista\n",
    "# När den sista filen är kontatinerad är databasen fullständigt uppdaterad\n",
    "db_list = []\n",
    "for i in range(len(transformed_list)):\n",
    "    databas = pd.concat([databas,transformed_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu sparar vi undan databasen som ett Pickle format - det är denna vi läser in och uppdaterar nästa vecka\n",
    "\n",
    "databas.to_pickle(\"databas.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### När databasen laddad. Flytta på de inlästa filerna och lägg upp nya, tomma filer, skapade från template filen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ny scannar vi igenom alla filer på old catalog och flyttat dem till den nya katalogen\n",
    "for folderName, subfolders, fileNames in os.walk(os.path.join(cpath,\"Input\")):\n",
    "    for names in fileNames:\n",
    "        shutil.move(os.path.join(cpath,folderName,names), os.path.join(cpath,\"InputLoaded\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Lägg upp nya tomma excelfiler. Plocka ut maxdatum på uppdaterad databas. Härled sedan de sju efterföljande dagarna. Det är dessa som ska läsas in från filen load_date_df som uppdateras varje år__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdate = databas.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skapar lista med de sju efterföljande dagarna \n",
    "date_list = []\n",
    "for i in range(7):\n",
    "    i +=1\n",
    "    date = maxdate + datetime.timedelta(days= i)\n",
    "    date_list.append(date)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plockar dessa datum från load_date_df, som innehåller filnam. Nyckel på date\n",
    "\n",
    "filename_df = load_date_df[load_date_df['Date'].isin(date_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = list(filename_df['filnamn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lägger upp nya filer\n",
    "for name in name_list:\n",
    "    shutil.copy(os.path.join(cpath,\"template\",\"template.xls\"),os.path.join(cpath,\"Input\",name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Först tar vi bort den existerande kodboken\n",
    "\n",
    "os.unlink(os.path.join(cpath,\"kodbok\",\"existing_kodbok.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sedan döper vi om kodbok till existing_kodbok.xls - nu är det den som är master\n",
    "\n",
    "shutil.move(os.path.join(cpath,\"kodbok\",\"kodbok.xls\"),os.path.join(cpath,\"kodbok\",\"existing_kodbok.xls\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
