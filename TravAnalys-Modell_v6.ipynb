{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ny modell. Nu delar vi upp datat på omgångarna, inte slumpmässigt. Totalt 222 omgångar. Bygger modell på 175 omgångar, validerar på de övriga. Imputerar för missing innan vi kör modellen, tar bort detta steg från data pipelinen. Vi läser även in VNUM som är rankingen efter spelade hästar för att jämföra med den framtagna modellen__\n",
    "\n",
    "__Tar fram optimal modell med cross validering och en randomforrest. Först en modell bara på v75% och VNUM för att plocka 21 hästar. Sedan en andra modell som använder Leffes rankingar för att idenfiera de hästar som inte fångas u__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Necessary Sklearn objects used in the analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_excel('DataV75TillUffeS20190525.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en unik nyckel på lopp: Gör om Datum och lopp till en sträng\n",
    "\n",
    "df0['cdate'] = df0.Datum.astype('object')\n",
    "df0['cLopp'] = df0.Lopp.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['Key'] = df0['cdate'].astype(str) + df0['cLopp'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Skapar en målvariabel - vinnare__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['Y'] = np.where(df0['Plac'].isin([1]), 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-05-25 00:00:00')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.Datum.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plockar bort de variabler som inte ska med__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Utdelning' 'S_R'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-346fffa06a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Alla analysvariabler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Utdelning'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Plac'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cdate'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cLopp'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'V_ODDS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'S_R'\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;34m'TK_R'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Arstid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Distans'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Startsatt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SP_R'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Ex_R'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'R_R'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'P_R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Utdelning' 'S_R'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df1 = df0.copy(deep = True)\n",
    "# Alla analysvariabler\n",
    "df1 = df1. \\\n",
    "drop(['Utdelning','Plac','cdate','cLopp','V_ODDS','S_R', \\\n",
    "      'TK_R','Arstid','Distans','Startsatt','SP_R','Ex_R','R_R','P_R'], axis = 1). \\\n",
    "copy().set_index(['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterera över varje kolumn och använd logiken nedan\n",
    "# Checkar dessa variabler [G_R , A_R, ToR , P_R ]\n",
    "# Skapar en lista som håller de unika datumen för dessa när missing förekommer\n",
    "# Tar sedan bort dessa lopp och bygger modell på de kvarvarande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['mflag1'] = np.where(df1.G_R.isna(),True,False)\n",
    "df1['mflag2'] = np.where(df1.A_R.isna(),True,False)\n",
    "df1['mflag3'] = np.where(df1.ToR.isna(),True,False)\n",
    "#df1['mflag4'] = np.where(df1.P_R.isna(),True,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_delete = df1[(df1.mflag1 | df1.mflag2 | df1.mflag3 | df1.mflag4)]\n",
    "\n",
    "df_delete = df1[(df1.mflag1 | df1.mflag2 | df1.mflag3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_filter = df_delete.Datum.drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.Datum.isin(date_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.drop(['mflag1', 'mflag2','mflag3','mflag4'], axis = 1)\n",
    "df1 = df1.drop(['mflag1', 'mflag2','mflag3'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gör om grupp till objekt\n",
    "df1['GRUPP'] = df1.GRUPP.astype('object')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Delar upp i numeriska samt charachter attribut. Det är dessa som går in i modellen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = [] \n",
    "cat_attribs = [] \n",
    "\n",
    "for var, typ in zip(df1.columns[:-1], df1.dtypes[:-1]): \n",
    "    if typ == 'object': \n",
    "        cat_attribs.append(var) \n",
    "    elif (typ != 'datetime64[ns]')  & (var != 'Hast') & (var != 'Lopp'): \n",
    "        num_attribs.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs.append('V75PROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu bygger vi upp en pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "# Denna klass måste vi göra för att särskilja numeriska variabler mot character variabler\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egen klass för att sätta dummyvariabler\n",
    "\n",
    "class SetDummyVar(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        tempdf = pd.get_dummies(X[self.attribute_names], columns = self.attribute_names)\n",
    "        return tempdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline för numeriska variabler\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('dummy_cat', SetDummyVar(cat_attribs)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu itererar vi över alla testloppen. Plockar de 24 högsta scorade hästarna__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__På VNUM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_list = []\n",
    "b_list = []\n",
    "d_list = df1.Datum.drop_duplicates().tolist()\n",
    "for date in d_list:\n",
    "    df_test1 = df1[df1.Datum == date].drop('Datum', axis = 1)\n",
    "    df_test1['Pred'] = np.where(df_test1.VNUM.isin([1,2,3]),1,0)\n",
    "    df_test1['Facit'] =  np.where((df_test1.Pred == 1) & (df_test1.Y == 1) ,1,0)\n",
    "    cm_list.append(df_test1.Facit.sum())\n",
    "    b_list.append(df_test1.Pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tp_tot = 0\n",
    "out_tot = 0\n",
    "for tp, tot in zip(cm_list,b_list):\n",
    "    tp_tot = tp_tot + tp\n",
    "    out_tot = out_tot + tot\n",
    "\n",
    "avg = tp_tot / len(cm_list)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_out_tot = out_tot/len(cm_list) \n",
    "avg_out_tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "avg/avg_out_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "avg/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Genom att plocka de tre högsta i VNUM för varje lopp så hittar vi 69% av de faktiska vinnarna. Bygg en modell på Leffes travstatstik för att hitta de som VNUM inte hittar. Modellen byggs på de hästar som inte ligger i VNUM 1,2 eller 3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[~df1.VNUM.isin([1,2,3])]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu plockar vi ut 52 (20%) v75 omgångar för att använda dem som test och utvärdera modellen på__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v75 = df2.Datum.drop_duplicates().to_frame()\n",
    "\n",
    "v75['is_test']=np.random.uniform(0,1,len(v75))<=0.2\n",
    "\n",
    "test, basedf = v75[v75['is_test']==True], v75[v75['is_test']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plockar in imgångarna vi ska träna modellen på\n",
    "train = df2[df2.Datum.isin(basedf.Datum.tolist())]\n",
    "\n",
    "# De 52 vi utvärderar på \n",
    "validate = df2[df2.Datum.isin(test.Datum.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['VLP',\n",
    " 'SVLP',\n",
    " 'VSVLP',\n",
    " 'VPN_SUM',\n",
    " 'VPN_SUM_ORD',\n",
    " 'VPK_SUM',\n",
    " 'VPK_SUM_ORD',\n",
    " 'VLPB',\n",
    " 'SVLPB',\n",
    " 'VSVLPB',\n",
    " 'E_P',\n",
    " 'E_P_Num',\n",
    " 'E_N',\n",
    " 'E_R',\n",
    " 'E_U',\n",
    " 'G_R',\n",
    " 'A_R',\n",
    " 'T_R',\n",
    " 'ToR',\n",
    " 'Ts_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Träningsdata\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_train = full_pipeline.fit_transform(train)\n",
    "## En array som håller det vi vill predikter\n",
    "label_train = train[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valideringsdata\n",
    "# Alla förklaringsvaribler i en multidimensionell array där kategrisvaribler har gjorts om till\n",
    "# dummyvariabler\n",
    "features_valid = full_pipeline.fit_transform(validate)\n",
    "## En array som håller det vi vill predikter\n",
    "label_valid = validate[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [500],\n",
    "    'max_leaf_nodes':[16],\n",
    "    'max_features': ['sqrt', 'auto','log2'],\n",
    "    'criterion': ['gini'],\n",
    "    'bootstrap': [True, False],\n",
    "    'n_jobs':[-1]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar instansen av modellen\n",
    "rf_all = RandomForestClassifier()\n",
    "\n",
    "# Instansen av gridsearc\n",
    "grid_search = GridSearchCV(rf_all, param_grid, cv=5, scoring = 'roc_auc' , return_train_score=True)\n",
    "# Hyperparameter oprimering\n",
    "grid_search.fit(features_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pararg = grid_search.best_params_\n",
    "pararg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utvärderar styrkan i modellen - sätter hyperparametrarna och cross fold fem\n",
    "rf_mod_6 = RandomForestClassifier(**pararg)\n",
    "scores_opt = cross_val_score(rf_mod_6, features_train, label_train , scoring = \"roc_auc\", cv = 5 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_opt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bygger den slutliga modellen för random forrest\n",
    "rf_mod_6.fit(features_train,label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu testar vi att bygga en enkel ensamble model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "n_neighbors = 25\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(**pararg)\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42, probability = True)\n",
    "kne_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf), ('kn', kne_clf)],\n",
    "    voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.fit(features_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, kne_clf, voting_clf):\n",
    "    clf.fit(features_train,label_train)\n",
    "    predict = clf.predict_proba(features_valid)\n",
    "    fpr, tpr, threshold = roc_curve(label_valid,predict[:,1])\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "    print(clf.__class__.__name__, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = rf_mod_6.predict_proba(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(label_valid,predict[:,1])\n",
    "\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu plockar vi de två högst scorade hästarna i varje lopp och utvärderar på valideringsdatat__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top(df):\n",
    "    return df.sort_values(['Lopp','Prob1'], ascending = [True, False])[['Prob1','Lopp','Y']].iloc[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_list = validate.Datum.drop_duplicates().tolist()\n",
    "res_list = []\n",
    "for date in d_list:\n",
    "    df_test1 = validate[validate.Datum == date].drop('Datum', axis = 1)\n",
    "    df_test1['GRUPP'] = df_test1.GRUPP.astype('object')\n",
    "    features = full_pipeline.fit_transform(df_test1)\n",
    "    predict = rf_mod_6.predict_proba(features)\n",
    "    predict_frame = pd.DataFrame({'Prob0':predict[:,0],'Prob1':predict[:,1]})\n",
    "    df_lopp = predict_frame.merge(df_test1.reset_index(), right_index = True, left_index = True)\n",
    "    grouped = df_lopp.groupby('Lopp')\n",
    "    result = grouped.apply(top).Y.sum()\n",
    "    res_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for res in res_list:\n",
    "    tot +=res\n",
    "avg = tot/len(res_list)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.8 + 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "\n",
    "6.9 / (21 + 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.9 / 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tar fram frekvenser av utfallet__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tar fram diagram på fördelningen. True-Positive\n",
    "# Gör en dataframe för att sedan gruppera\n",
    "\n",
    "tp = {'TP':res_list}\n",
    "tp_frame = pd.DataFrame.from_dict(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_frame.TP.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = round(tp_frame.TP.value_counts().sort_index()/len(test)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(1, 1, figsize=(12,8))\n",
    "\n",
    "ax1.bar(koll.index.tolist(), dist, color=(0.2, 0.4, 0.6, 1))\n",
    "\n",
    "for x, y in zip(koll.index.tolist(), koll):\n",
    "    ax1.text(x,y+0.5,str(int(round(y)))+'%', ha = 'center', fontsize=14)\n",
    "    \n",
    "ax1.set_title('Utvärderat på 35 omgångar - 14 hästar uttagna i varje omgång, VNUM 1-3 exkluderat')\n",
    "\n",
    "ax1.set_ybound(0,60)\n",
    "\n",
    "save_fig('DistRes25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu bygger vi en modell på hela datamängden med de optimerade hyperparametrarna och utvärderer med cross fold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# Pipelineobjekt\n",
    "joblib.dump(full_pipeline, 'Pipeline_v6.pkl')\n",
    "\n",
    "# Modellobjekt\n",
    "joblib.dump(rf_mod_6, 'Travmodel_v6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
