{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Adderar nytt data för att uppdatera modellen. Nytt data från 20190820 och framåt__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tar fram en modell med logistisk regression. En för data innan 2019 och en för 2019 för att se om något förändrats i data. Det ser vi genom att titta på modelparametrar__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Sklearn objects used in the analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split \n",
    "import sklearn.preprocessing as preproc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = os.getcwd()\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_excel('DataV75Outtake20190820.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en unik nyckel på lopp: Gör om Datum och lopp till en sträng\n",
    "\n",
    "df0['cdate'] = df0.Datum.astype('object')\n",
    "df0['cLopp'] = df0.Lopp.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['Key'] = df0['cdate'].astype(str) + df0['cLopp'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Skapar en målvariabel - vinnare__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['Y'] = np.where(df0['Plac'].isin([1]), 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plockar bort de variabler som inte ska med__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alla analysvariabler\n",
    "df1 = df0.copy(deep = True).set_index(['Key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plockar bort alla vnum 1-3, de ska med i uttaget\n",
    "# Plockar bort hästara i VNUM (1,2,3) som inte ska vara med\n",
    "df1 = df1[~df1.VNUM.isin([1,2,3])]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plockar bort de variabler som inte ska med__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alla analysvariabler\n",
    "df1 = df1.drop(['Plac','cdate','cLopp','TK_R','Arstid','Startsatt', 'VNUM', 'GRUPP', 'Distans',\n",
    "               'cLopp','cdate','V75PROC', 'V_ODDS',  'SP_R','E_R'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21897 entries, 2016-05-21 00:00:001 to 2019-08-14 00:00:007\n",
      "Data columns (total 26 columns):\n",
      "Datum          21897 non-null datetime64[ns]\n",
      "Lopp           21897 non-null int64\n",
      "Hast           21897 non-null int64\n",
      "VLP            21897 non-null float64\n",
      "SVLP           21897 non-null float64\n",
      "VSVLP          21897 non-null float64\n",
      "VPN_SUM        21897 non-null float64\n",
      "VPN_SUM_ORD    21897 non-null int64\n",
      "VPK_SUM        21897 non-null float64\n",
      "VPK_SUM_ORD    21601 non-null float64\n",
      "VLPB           21897 non-null float64\n",
      "SVLPB          21897 non-null float64\n",
      "VSVLPB         21897 non-null float64\n",
      "E_P            21897 non-null float64\n",
      "E_P_Num        21897 non-null int64\n",
      "E_N            21897 non-null float64\n",
      "E_U            20856 non-null float64\n",
      "G_R            20061 non-null float64\n",
      "A_R            18580 non-null float64\n",
      "T_R            20220 non-null float64\n",
      "ToR            19034 non-null float64\n",
      "P_R            19501 non-null float64\n",
      "Ex_R           13490 non-null float64\n",
      "R_R            13882 non-null float64\n",
      "Ts_R           21897 non-null int64\n",
      "Y              21897 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(19), int64(6)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = [] \n",
    "cat_attribs = [] \n",
    "\n",
    "for var, typ in zip(df1.columns[:-1], df1.dtypes[:-1]): \n",
    "    if typ == 'object': \n",
    "        cat_attribs.append(var) \n",
    "    elif (typ != 'datetime64[ns]')  & (var != 'Hast') & (var != 'Lopp'): \n",
    "        num_attribs.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_attribs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VLP',\n",
       " 'SVLP',\n",
       " 'VSVLP',\n",
       " 'VPN_SUM',\n",
       " 'VPN_SUM_ORD',\n",
       " 'VPK_SUM',\n",
       " 'VPK_SUM_ORD',\n",
       " 'VLPB',\n",
       " 'SVLPB',\n",
       " 'VSVLPB',\n",
       " 'E_P',\n",
       " 'E_P_Num',\n",
       " 'E_N',\n",
       " 'E_U',\n",
       " 'G_R',\n",
       " 'A_R',\n",
       " 'T_R',\n",
       " 'ToR',\n",
       " 'P_R',\n",
       " 'Ex_R',\n",
       " 'R_R',\n",
       " 'Ts_R']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nu bygger vi upp en pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulf/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "# Denna klass måste vi göra för att särskilja numeriska variabler mot character variabler\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# Egen klass för att sätta dummyvariabler\n",
    "\n",
    "class SetDummyVar(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        tempdf = pd.get_dummies(X[self.attribute_names], columns = self.attribute_names)\n",
    "        return tempdf.values\n",
    "\n",
    "# Pipeline för numeriska variabler\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('dummy_cat', SetDummyVar(cat_attribs)),\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy(deep = True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bygger modellen__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = full_pipeline.fit_transform(df2)\n",
    "## En array som håller det vi vill predikter\n",
    "label = df2[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77639685, 0.71764316, 0.77316319, 0.7677373 , 0.76020347])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"liblinear\", C = 0.1, random_state=42)\n",
    "\n",
    "# Utvärderar styrkan i modellen - sätter hyperparametrarna och cross fold fem\n",
    "scores_opt_spik = cross_val_score(log_clf, features,label, scoring = \"roc_auc\", cv = 5 ) \n",
    "\n",
    "scores_opt_spik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7590287947687103"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt_spik.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bygger modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7610574923115534\n"
     ]
    }
   ],
   "source": [
    "model_2019 = log_clf.fit(features,label)\n",
    "\n",
    "log_clf.fit(features,label)\n",
    "predict19 = log_clf.predict_proba(features)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(label,predict19[:,1])\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLP: 0.004: 1.0\n",
      "SVLP: -0.005: 0.99\n",
      "VSVLP: -0.097: 0.91\n",
      "VPN_SUM: 0.336: 1.4\n",
      "VPN_SUM_ORD: -0.053: 0.95\n",
      "VPK_SUM: 0.304: 1.36\n",
      "VPK_SUM_ORD: -0.051: 0.95\n",
      "VLPB: 0.007: 1.01\n",
      "SVLPB: -0.041: 0.96\n",
      "VSVLPB: 0.021: 1.02\n",
      "E_P: -0.249: 0.78\n",
      "E_P_Num: -0.057: 0.94\n",
      "E_N: -0.006: 0.99\n",
      "E_U: -0.008: 0.99\n",
      "G_R: 0.158: 1.17\n",
      "A_R: 0.138: 1.15\n",
      "T_R: 0.073: 1.08\n",
      "ToR: 0.044: 1.05\n",
      "P_R: 0.122: 1.13\n",
      "Ex_R: 0.031: 1.03\n",
      "R_R: 0.068: 1.07\n",
      "Ts_R: 0.107: 1.11\n"
     ]
    }
   ],
   "source": [
    "c_list_19 = model_2019.coef_.tolist()\n",
    "\n",
    "import math\n",
    "\n",
    "for var,par in zip(num_attribs, c_list_19[0]):\n",
    "    OddsRatio = math.exp(float(par))\n",
    "    print(var +':', str(round(par,3)) + ':', round(OddsRatio,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['VPN_SUM','VPK_SUM','E_P','G_R','A_R','P_R','Ts_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nu tar vi enbart med de som har en ODDSkvot under 0.9 samt över 1.1 och bygger en modell med alla interaktioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['VPN_SUM','VPK_SUM','E_P','G_R','A_R','P_R','Ts_R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ulf/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Bygger en ny pipeline på de valda variblerna\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "# Denna klass måste vi göra för att särskilja numeriska variabler mot character variabler\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# Egen klass för att sätta dummyvariabler\n",
    "\n",
    "class SetDummyVar(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        tempdf = pd.get_dummies(X[self.attribute_names], columns = self.attribute_names)\n",
    "        return tempdf.values\n",
    "\n",
    "# Pipeline för numeriska variabler\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\"))\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('dummy_cat', SetDummyVar(cat_attribs)),\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_red = full_pipeline.fit_transform(df2)\n",
    "## En array som håller det vi vill predikter\n",
    "label_red = df2[\"Y\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = preproc.PolynomialFeatures(include_bias = False).fit_transform(features_red) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21897, 35)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77561219, 0.71318904, 0.76680235, 0.76575962, 0.75670566])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"liblinear\", C = 0.1, random_state=42)\n",
    "\n",
    "# Utvärderar styrkan i modellen - sätter hyperparametrarna och cross fold fem\n",
    "scores_opt_red = cross_val_score(log_clf, features_red,label_red, scoring = \"roc_auc\", cv = 5 ) \n",
    "\n",
    "scores_opt_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556137728971769"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_opt_red.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7560124988000232\n"
     ]
    }
   ],
   "source": [
    "model_2019_red = log_clf.fit(features_red,label_red)\n",
    "\n",
    "log_clf.fit(features_red,label_red)\n",
    "predict19_red = log_clf.predict_proba(features_red)\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(label_red,predict19_red[:,1])\n",
    "roc_auc = auc(fpr,tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list_19_red = model_2019_red.coef_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VPN_SUM', 'VPK_SUM', 'E_P', 'G_R', 'A_R', 'P_R', 'Ts_R']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Oddskvot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VPN_SUM</td>\n",
       "      <td>0.755332</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VPK_SUM</td>\n",
       "      <td>0.958573</td>\n",
       "      <td>2.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E_P</td>\n",
       "      <td>-0.349813</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G_R</td>\n",
       "      <td>0.177293</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_R</td>\n",
       "      <td>0.191708</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P_R</td>\n",
       "      <td>0.171846</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ts_R</td>\n",
       "      <td>0.186135</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank  Parameter  Oddskvot\n",
       "0  VPN_SUM   0.755332      2.13\n",
       "1  VPK_SUM   0.958573      2.61\n",
       "2      E_P  -0.349813      0.70\n",
       "3      G_R   0.177293      1.19\n",
       "4      A_R   0.191708      1.21\n",
       "5      P_R   0.171846      1.19\n",
       "6     Ts_R   0.186135      1.20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = []\n",
    "parlist = []\n",
    "oddsr = []\n",
    "for var, par in zip(num_attribs, c_list_19_red[0]):\n",
    "    OddsRatio = math.exp(float(par))\n",
    "    rank.append(var)\n",
    "    parlist.append(par)\n",
    "    oddsr.append(round(OddsRatio,2)) \n",
    "    \n",
    "dictlist = {'Rank':rank, 'Parameter': parlist, 'Oddskvot': oddsr}\n",
    "# Konverterar till Dataframe\n",
    "df_val_19 = pd.DataFrame.from_dict(dictlist)\n",
    "df_val_19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Travmodel_v9.pkl']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#Pipelineobjekt\n",
    "joblib.dump(full_pipeline, 'Pipeline_v9.pkl')\n",
    "\n",
    "# Modellobjekt\n",
    "joblib.dump(model_2019_red, 'Travmodel_v9.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
